{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"gol-predictor.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNDCmJ8e/nKl1BJiFucBxxp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"0gXdjC5gjNgN"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"vegPiyEbkuW3"},"source":["Mount Google Drive"]},{"cell_type":"code","metadata":{"id":"uo-6xb70j9f7"},"source":["if 'google.colab' in str(get_ipython()):\n","  from google.colab import drive\n","  drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jmKlajxPq6Qb"},"source":["import numpy as np\n","import h5py\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.data import Dataset \n","from tensorflow.keras import Model\n","from tensorflow.keras.layers import Dense, Conv2D, Input\n","from tensorflow.keras.callbacks import EarlyStopping"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzVuhJrv0MRY"},"source":["%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qzZUug-6j-D3"},"source":["Paths and variables"]},{"cell_type":"code","metadata":{"id":"WAlVjid1kye3"},"source":["DATA_FILE_PATH = '/content/drive/MyDrive/GOL/data/game_of_life_100-100000.h5'\n","H5PY_DATASET_NAME = 'gol_frames'\n","FRAME_SIZE = 100\n","N_SERIES = 5\n","EPOCHS = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHrCmY3ejtHb"},"source":["## Loading and preprocessing"]},{"cell_type":"markdown","metadata":{"id":"tu_Zubo6M53x"},"source":["noisy_movies = np.zeros((n_samples, n_frames, row, col, 1), dtype=np.int)"]},{"cell_type":"code","metadata":{"id":"oMHOsK5hWLBT"},"source":["def DataGenerator(batch_size, h5_path, data_share=None):\n","  with h5py.File(h5_path, 'r') as f:\n","    if data_share == None:\n","      dataset = f[H5PY_DATASET_NAME]\n","    else:\n","      dataset = f[H5PY_DATASET_NAME][:data_share]\n","    counter = 0\n","    while True:\n","      input_frames = np.zeros((batch_size, N_SERIES, FRAME_SIZE, FRAME_SIZE, 1), dtype=np.int)\n","      output_frame = np.zeros((batch_size, 1, FRAME_SIZE, FRAME_SIZE, 1), dtype=np.int)\n","      if (counter + batch_size >= len(dataset)):\n","        counter = 0\n","      for i in range(batch_size):\n","        input_frames[i] = np.expand_dims(dataset[counter+i:counter+i+N_SERIES], axis=3)\n","        output_frame[i] = np.expand_dims(dataset[counter+i+N_SERIES], axis=2)\n","      yield (input_frames, output_frame)\n","      counter += batch_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYtt1871dpgU"},"source":["generator = DataGenerator(1, DATA_FILE_PATH, data_share=200)\n","x, y = next(generator)\n","print(f'X shape: {x.shape}.')\n","print(f'Y shape: {y.shape}.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t-AvJTKpNw-7"},"source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","seq = keras.Sequential(\n","    [\n","        keras.Input(shape=(None, 100, 100, 1)),\n","        layers.ConvLSTM2D(\n","            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n","        ),\n","        layers.BatchNormalization(),\n","        layers.ConvLSTM2D(\n","            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n","        ),\n","        layers.BatchNormalization(),\n","        layers.ConvLSTM2D(\n","            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n","        ),\n","        layers.BatchNormalization(),\n","        layers.ConvLSTM2D(\n","            filters=40, kernel_size=(3, 3), padding=\"same\", return_sequences=True\n","        ),\n","        layers.BatchNormalization(),\n","        layers.Conv3D(\n","            filters=1, kernel_size=(3, 3, 3), activation=\"sigmoid\", padding=\"same\"\n","        ),\n","    ]\n",")\n","seq.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\",  metrics=['acc'])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipzROgFIOWsM"},"source":["generator = DataGenerator(10, DATA_FILE_PATH, data_share=500)\n","\n","seq.fit(generator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNXOR9OvFpcP"},"source":["# generator = DataGenerator()\n","\n","# for _ in range(2):\n","#   fig, axs = plt.subplots(1,2, figsize=(10, 10))\n","#   input, output = next(generator)\n","#   axs[0].imshow(input[-1][:,:,0])\n","#   axs[0].set_title('Input')\n","#   axs[1].imshow(output[0][:,:,0])\n","#   axs[1].set_title('Output')\n","#   plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbBt4S7By1-Y"},"source":["# es_callback = EarlyStopping('accuracy', min_delta=0.1, patience=1, restore_best_weights=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RSYVZjNcXau"},"source":["# def model():\n","#   input = Input(shape=[100,100,1])\n","#   output = Conv2D(3, (3, 3), activation='relu', padding='same', input_shape=(100, 100, N_SERIES))(input)\n","\n","#   model = Model(inputs=input, outputs=output)\n","#   model.compile(optimizer='Adam', loss='mse', metrics=['accuracy'])\n","#   return model\n","\n","# generator = DataGenerator()\n","# model = model()\n","# h = model.fit(generator, epochs=EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbDSZ6BvrmL9"},"source":["# generator = DataGenerator()\n","# x, y = next(generator) \n","# predictions = model.predict()"],"execution_count":null,"outputs":[]}]}